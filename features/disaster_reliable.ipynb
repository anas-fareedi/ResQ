{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "293c30e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Study\\Learn ML\\DL\\env-tf-gpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea94c62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_22352\\4190944023.py:7: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df  = pd.read_csv(BASE_PATH + \"disaster_response_messages_training.csv\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Base path\n",
    "BASE_PATH = \"../data/raw/\"\n",
    "\n",
    "# Load datasets\n",
    "df  = pd.read_csv(BASE_PATH + \"disaster_response_messages_training.csv\")\n",
    "dft = pd.read_csv(BASE_PATH + \"disaster_response_messages_test.csv\")\n",
    "dfv = pd.read_csv(BASE_PATH + \"disaster_response_messages_validation.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0eddf39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_22352\\1968534392.py:2: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dft = pd.read_csv(\"../data/raw/disaster_response_messages_training.csv\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/raw/disaster_response_messages_test.csv\")\n",
    "dft = pd.read_csv(\"../data/raw/disaster_response_messages_training.csv\")\n",
    "dfv = pd.read_csv(\"../data/raw/disaster_response_messages_validation.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "40a3581b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_MAP = {\n",
    "    0: \"real_disaster\",\n",
    "    1: \"fake_casual\",\n",
    "    2: \"noise_gibberish\"\n",
    "}\n",
    "\n",
    "NUM_LABELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b561329e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def label_message(text):\n",
    "    text = text.lower().strip()\n",
    "\n",
    "    # ---------- 2️⃣ Noise / gibberish ----------\n",
    "    # very short or random-looking text\n",
    "    if len(text) < 6:\n",
    "        return 2\n",
    "\n",
    "    alpha_chars = sum(c.isalpha() for c in text)\n",
    "    if alpha_chars / max(len(text), 1) < 0.6:\n",
    "        return 2\n",
    "\n",
    "    # ---------- 1️⃣ Fake / casual ----------\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"\n",
    "        \"\\U0001F600-\\U0001F64F\"\n",
    "        \"\\U0001F300-\\U0001F5FF\"\n",
    "        \"\\U0001F680-\\U0001F6FF\"\n",
    "        \"\\U0001F1E0-\\U0001F1FF\"\n",
    "        \"]+\",\n",
    "        flags=re.UNICODE\n",
    "    )\n",
    "\n",
    "    casual_words = [\"hey\", \"hi\", \"lol\", \"bro\", \"dude\", \"haha\", \"jk\"]\n",
    "\n",
    "    if emoji_pattern.search(text):\n",
    "        return 1\n",
    "\n",
    "    if any(word in text for word in casual_words):\n",
    "        return 1\n",
    "\n",
    "    if re.search(r\"(.)\\1{3,}\", text):  # fireeee\n",
    "        return 1\n",
    "\n",
    "    # ---------- 0️⃣ Real disaster ----------\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9d364c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    1568\n",
       "1    1054\n",
       "2       7\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"] = df[\"message\"].apply(label_message)\n",
    "df[\"label\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "facb2305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 2103\n",
      "Validation size: 526\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    df[\"message\"].values,\n",
    "    df[\"label\"].values,         \n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df[\"label\"]       \n",
    ")\n",
    "\n",
    "print(\"Train size:\", len(X_train))\n",
    "print(\"Validation size:\", len(X_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0efabe39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train label distribution: [1254  843    6]\n",
      "Val label distribution: [314 211   1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Train label distribution:\", np.bincount(y_train))\n",
    "print(\"Val label distribution:\", np.bincount(y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "42ae0346",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\n",
    "    \"distilbert-base-uncased\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "88cd91dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeNewsDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        encoding = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3838630a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_gibberish(text, min_len=6, min_alpha_ratio=0.6):\n",
    "    text = text.strip()\n",
    "\n",
    "    if len(text) < min_len:\n",
    "        return True\n",
    "\n",
    "    alpha_chars = sum(c.isalpha() for c in text)\n",
    "    if alpha_chars / max(len(text), 1) < min_alpha_ratio:\n",
    "        return True\n",
    "\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e6f069fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FakeNewsDataset(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    tokenizer\n",
    ")\n",
    "\n",
    "val_dataset = FakeNewsDataset(\n",
    "    X_val,\n",
    "    y_val,\n",
    "    tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4361ef77",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b3a417d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=3  \n",
    ")\n",
    "\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "def29759",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr=2e-5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b7c92370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 - Training Loss: 0.7188\n",
      "Epoch 2/3 - Training Loss: 0.5246\n",
      "Epoch 3/3 - Training Loss: 0.3012\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Training Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e06f215e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved successfully.\n"
     ]
    }
   ],
   "source": [
    "SAVE_PATH = \"fake_detection_distilbert\"\n",
    "\n",
    "model.save_pretrained(SAVE_PATH)\n",
    "tokenizer.save_pretrained(SAVE_PATH)\n",
    "\n",
    "print(\"Model and tokenizer saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "53b90860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference model loaded.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizerFast\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "infer_tokenizer = DistilBertTokenizerFast.from_pretrained(SAVE_PATH)\n",
    "infer_model = DistilBertForSequenceClassification.from_pretrained(SAVE_PATH)\n",
    "\n",
    "infer_model.to(device)\n",
    "infer_model.eval()\n",
    "\n",
    "print(\"Inference model loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ce716a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "\n",
    "LABEL_MAP = {\n",
    "    0: \"real_disaster\",\n",
    "    1: \"fake_casual\",\n",
    "    2: \"noise_gibberish\"\n",
    "}\n",
    "\n",
    "\n",
    "def detect_fake(message):\n",
    "    message_lower = message.lower().strip()\n",
    "    \n",
    "        # 0️⃣ Gibberish guard (ABSOLUTELY REQUIRED)\n",
    "    if is_gibberish(message_lower):\n",
    "        return {\n",
    "            \"is_fake\": True,\n",
    "            \"class\": \"noise_gibberish\",\n",
    "            \"reason\": \"gibberish_guard\"\n",
    "        }\n",
    "\n",
    "    # ---------- Heuristic check (emoji) ----------\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"\n",
    "        \"\\U0001F600-\\U0001F64F\"\n",
    "        \"\\U0001F300-\\U0001F5FF\"\n",
    "        \"\\U0001F680-\\U0001F6FF\"\n",
    "        \"\\U0001F1E0-\\U0001F1FF\"\n",
    "        \"]+\",\n",
    "        flags=re.UNICODE\n",
    "    )\n",
    "\n",
    "    if emoji_pattern.search(message_lower):\n",
    "        return {\n",
    "            \"is_fake\": True,\n",
    "            \"class\": \"fake_casual\",\n",
    "            \"reason\": \"emoji_detected\"\n",
    "        }\n",
    "\n",
    "    # ---------- Model-based check ----------\n",
    "    encoding = infer_tokenizer(\n",
    "        message,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    input_ids = encoding[\"input_ids\"].to(device)\n",
    "    attention_mask = encoding[\"attention_mask\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = infer_model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "\n",
    "        probs = torch.softmax(outputs.logits, dim=1)\n",
    "        pred = torch.argmax(probs, dim=1).item()\n",
    "        confidence = probs[0][pred].item()\n",
    "\n",
    "    predicted_class = LABEL_MAP[pred]\n",
    "\n",
    "    return {\n",
    "        \"is_fake\": pred != 0,                   \n",
    "        \"class\": predicted_class,               \n",
    "        \"model_confidence\": round(confidence, 3)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "87f55a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invalid_message(text):\n",
    "    if len(text.strip()) < 6:\n",
    "        return True\n",
    "\n",
    "    alpha = sum(c.isalpha() for c in text)\n",
    "    if alpha / len(text) < 0.6:\n",
    "        return True\n",
    "\n",
    "    if not any(word in text.lower() for word in [\n",
    "        \"fire\", \"flood\", \"earthquake\", \"storm\", \"help\", \"injured\"\n",
    "    ]):\n",
    "        return True\n",
    "\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7d31d9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 1\n",
      "Message: Weather update - a cold front from Cuba that could pass over Haiti\n",
      "Fake: False\n",
      "Confidence: 0.95\n",
      "\n",
      "Sample 2\n",
      "Message: Is the Hurricane over or is it not over\n",
      "Fake: False\n",
      "Confidence: 0.968\n",
      "\n",
      "Sample 3\n",
      "Message: says: west side of Haiti, rest of the country today and tonight\n",
      "Fake: False\n",
      "Confidence: 0.918\n",
      "\n",
      "Sample 4\n",
      "Message: Information about the National Palace-\n",
      "Fake: False\n",
      "Confidence: 0.923\n",
      "\n",
      "Sample 5\n",
      "Message: Storm at sacred heart of jesus\n",
      "Fake: False\n",
      "Confidence: 0.947\n",
      "\n",
      "Sample 6\n",
      "Message: Please, we need tents and water. We are in Silo, Thank you!\n",
      "Fake: False\n",
      "Confidence: 0.979\n",
      "\n",
      "Sample 7\n",
      "Message: I would like to receive the messages, thank you\n",
      "Fake: False\n",
      "Confidence: 0.98\n",
      "\n",
      "Sample 8\n",
      "Message: There's nothing to eat and water, we starving and thirsty.\n",
      "Fake: True\n",
      "Confidence: 0.98\n",
      "\n",
      "Sample 9\n",
      "Message: I am in Petionville. I need more information regarding 4636\n",
      "Fake: False\n",
      "Confidence: 0.975\n",
      "\n",
      "Sample 10\n",
      "Message: I am in Thomassin number 32, in the area named Pyron. I would like to have some water. Thank God we are fine, but we desperately need water. Thanks\n",
      "Fake: False\n",
      "Confidence: 0.966\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i, msg in enumerate(dft[\"message\"].head(10)):\n",
    "    result = detect_fake(msg)\n",
    "\n",
    "    is_fake = result.get(\"is_fake\")\n",
    "    confidence = result.get(\"model_confidence\", \"N/A\")\n",
    "\n",
    "    print(f\"\\nSample {i+1}\")\n",
    "    print(\"Message:\", msg)\n",
    "    print(\"Fake:\", is_fake)\n",
    "    print(\"Confidence:\", confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb45ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'is_fake': False, 'class': 'real_disaster', 'model_confidence': 0.753}\n"
     ]
    }
   ],
   "source": [
    "custom_message = \"jgviyivuifvuy\"\n",
    "print(detect_fake(custom_message))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "88bc8e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'is_fake': False, 'class': 'real_disaster', 'model_confidence': 0.975}\n"
     ]
    }
   ],
   "source": [
    "print(detect_fake(\"I met with an accident at the hills 10 peoples affected, need help\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
