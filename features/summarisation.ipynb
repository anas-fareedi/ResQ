{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4c19d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ACER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\ACER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x269d75b2650>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "torch.manual_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "075d78fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fefc9830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertModel(\n",
       "  (embeddings): Embeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (layer): ModuleList(\n",
       "      (0-5): 6 x TransformerBlock(\n",
       "        (attention): DistilBertSdpaAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = DistilBertModel.from_pretrained(MODEL_NAME)\n",
    "\n",
    "model.eval()  # inference only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5c0447c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentence(sentence):\n",
    "    inputs = tokenizer(\n",
    "        sentence,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        padding=True\n",
    "    )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # CLS token embedding\n",
    "    cls_embedding = outputs.last_hidden_state[:, 0, :].numpy()\n",
    "    return cls_embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bb5ef9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_message(text):\n",
    "    if not isinstance(text, str):\n",
    "        return False\n",
    "    if len(text.strip()) < 10:\n",
    "        return False\n",
    "    if text.isupper():\n",
    "        return False\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b0163a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def is_meaningful_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return False\n",
    "\n",
    "    text = text.strip()\n",
    "\n",
    "    # Too short\n",
    "    if len(text) < 15:\n",
    "        return False\n",
    "\n",
    "    # No vowels → likely gibberish\n",
    "    if not re.search(r\"[aeiouAEIOU]\", text):\n",
    "        return False\n",
    "\n",
    "    # Repeated random characters\n",
    "    if len(set(text)) < 5:\n",
    "        return False\n",
    "\n",
    "    # Single-word junk\n",
    "    if len(text.split()) < 3:\n",
    "        return False\n",
    "\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "07163966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_sentence_split(text):\n",
    "    try:\n",
    "        return sent_tokenize(text)\n",
    "    except:\n",
    "        # fallback: simple rule-based split\n",
    "        return [s.strip() for s in text.split(\".\") if len(s.strip()) > 5]\n",
    "    \n",
    "    \n",
    "def generate_summary(message, max_sentences=2):\n",
    "    if not is_meaningful_text(message):\n",
    "        return None   # or \"Invalid / noise message\"\n",
    "\n",
    "    sentences = safe_sentence_split(message)\n",
    "\n",
    "    if len(sentences) <= max_sentences:\n",
    "        return message.strip()\n",
    "\n",
    "    embeddings = np.vstack([encode_sentence(s) for s in sentences])\n",
    "    centroid = embeddings.mean(axis=0, keepdims=True)\n",
    "\n",
    "    scores = cosine_similarity(embeddings, centroid).flatten()\n",
    "    top_ids = np.argsort(scores)[::-1][:max_sentences]\n",
    "\n",
    "    return \" \".join([sentences[i] for i in top_ids])\n",
    "\n",
    "\n",
    "# def generate_summary(message, max_sentences=2):\n",
    "#     if not is_valid_message(message):\n",
    "#         return \"Message not suitable for summarization.\"\n",
    "    \n",
    "#     sentences = safe_sentence_split(message)\n",
    "    \n",
    "#     if len(sentences) <= max_sentences:\n",
    "#         return message.strip()\n",
    "    \n",
    "#     sentence_embeddings = np.vstack(\n",
    "#         [encode_sentence(s) for s in sentences]\n",
    "#     )\n",
    "    \n",
    "#     document_embedding = np.mean(sentence_embeddings, axis=0, keepdims=True)\n",
    "    \n",
    "#     similarities = cosine_similarity(sentence_embeddings, document_embedding)\n",
    "    \n",
    "#     ranked_indices = np.argsort(similarities.flatten())[::-1]\n",
    "    \n",
    "#     selected_sentences = [\n",
    "#         sentences[i] for i in ranked_indices[:max_sentences]\n",
    "#     ]\n",
    "    \n",
    "#     return \". \".join(selected_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ced7e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MESSAGE: People are trapped on rooftops. Water level is rising fast. Need immediate rescue.\n",
      "SUMMARY: People are trapped on rooftops. Need immediate rescue.\n",
      "--------------------------------------------------------------------------------\n",
      "MESSAGE: \n",
      "Heavy rainfall has been continuing for the past 36 hours in the low-lying areas near the river.\n",
      "Several houses are completely submerged and many families have moved to rooftops to save themselves.\n",
      "Water levels are still rising rapidly and strong currents are making rescue operations difficult.\n",
      "Electricity has been cut off in most areas and mobile networks are unstable.\n",
      "There is an urgent need for boats, food packets, clean drinking water, and medical assistance, especially for elderly people and children.\n",
      "Some people are injured and unable to move, while others are trapped inside partially collapsed houses.\n",
      "Local authorities have been informed, but immediate external help is required to prevent loss of life.\n",
      "\n",
      "SUMMARY: Water levels are still rising rapidly and strong currents are making rescue operations difficult. There is an urgent need for boats, food packets, clean drinking water, and medical assistance, especially for elderly people and children.\n",
      "--------------------------------------------------------------------------------\n",
      "MESSAGE: gyuvuyjujvujv. jbjyuy\n",
      "SUMMARY: None\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_messages = [\n",
    "    \"People are trapped on rooftops. Water level is rising fast. Need immediate rescue.\",\n",
    " \"\"\"\n",
    "Heavy rainfall has been continuing for the past 36 hours in the low-lying areas near the river.\n",
    "Several houses are completely submerged and many families have moved to rooftops to save themselves.\n",
    "Water levels are still rising rapidly and strong currents are making rescue operations difficult.\n",
    "Electricity has been cut off in most areas and mobile networks are unstable.\n",
    "There is an urgent need for boats, food packets, clean drinking water, and medical assistance, especially for elderly people and children.\n",
    "Some people are injured and unable to move, while others are trapped inside partially collapsed houses.\n",
    "Local authorities have been informed, but immediate external help is required to prevent loss of life.\n",
    "\"\"\",\n",
    "\"gyuvuyjujvujv. jbjyuy\"\n",
    "]\n",
    "\n",
    "for msg in test_messages:\n",
    "    print(\"MESSAGE:\", msg)\n",
    "    print(\"SUMMARY:\", generate_summary(msg))\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55015941",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_20060\\4190944023.py:7: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df  = pd.read_csv(BASE_PATH + \"disaster_response_messages_training.csv\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Base path\n",
    "BASE_PATH = \"../data/raw/\"\n",
    "\n",
    "# Load datasets\n",
    "df  = pd.read_csv(BASE_PATH + \"disaster_response_messages_training.csv\")\n",
    "dft = pd.read_csv(BASE_PATH + \"disaster_response_messages_test.csv\")\n",
    "dfv = pd.read_csv(BASE_PATH + \"disaster_response_messages_validation.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9067234e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = dft.copy()\n",
    "dft[\"message\"] = dft[\"message\"].astype(str).fillna(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f20cc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "dft[\"summary\"] = dft[\"message\"].apply(generate_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2624905a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MESSAGE:\n",
      "Hello, what can be done to find a good answer from 4636\n",
      "\n",
      "SUMMARY:\n",
      "Hello, what can be done to find a good answer from 4636\n",
      "====================================================================================================\n",
      "MESSAGE:\n",
      "I am Pestel, there is no food, there is nothing. We are at Dipi's house, please, we are waiting for you \n",
      "\n",
      "SUMMARY:\n",
      "I am Pestel, there is no food, there is nothing. We are at Dipi's house, please, we are waiting for you\n",
      "====================================================================================================\n",
      "MESSAGE:\n",
      "how some one can send his colum vital for jobpam.com if he gets it on his jump? \n",
      "\n",
      "SUMMARY:\n",
      "how some one can send his colum vital for jobpam.com if he gets it on his jump?\n",
      "====================================================================================================\n",
      "MESSAGE:\n",
      "- Additional accommodation for visiting staff would be secured through hiring rooms at hotels in Mansehra; more staff than capacity is presently accommodated at the office premises in Mansehra.\n",
      "\n",
      "SUMMARY:\n",
      "- Additional accommodation for visiting staff would be secured through hiring rooms at hotels in Mansehra; more staff than capacity is presently accommodated at the office premises in Mansehra.\n",
      "====================================================================================================\n",
      "MESSAGE:\n",
      "Schools and kindergartens were closed Tuesday afternoon, and ferry services to outlying islands were suspended as the fast-moving storm closed in on the high-rise city of 6.9 million.\n",
      "\n",
      "SUMMARY:\n",
      "Schools and kindergartens were closed Tuesday afternoon, and ferry services to outlying islands were suspended as the fast-moving storm closed in on the high-rise city of 6.9 million.\n",
      "====================================================================================================\n",
      "MESSAGE:\n",
      "Hello Digicel. I'm looking for work. We have found food but haven't found a tent. \n",
      "\n",
      "SUMMARY:\n",
      "I'm looking for work.. We have found food but haven't found a tent.\n",
      "====================================================================================================\n",
      "MESSAGE:\n",
      "I am a 4th year agriculture student. I live at Lalue 233 \n",
      "\n",
      "SUMMARY:\n",
      "I am a 4th year agriculture student. I live at Lalue 233\n",
      "====================================================================================================\n",
      "MESSAGE:\n",
      "ir for youth. .. . we are counting on you and we are thanking you for your contribution. we are waiting for your response\n",
      "\n",
      "SUMMARY:\n",
      "we are waiting for your response. ir for youth.\n",
      "====================================================================================================\n",
      "MESSAGE:\n",
      "That's too much. .. Our Archibishop is gone. Our priest and seminarist, most of them are dead. Our training centres are destroyed. This is the reason why I am asking you to help me to complete the rest of the school year wherever you can. ..\n",
      "\n",
      "SUMMARY:\n",
      ".. Our Archibishop is gone.. ..\n",
      "====================================================================================================\n",
      "MESSAGE:\n",
      "Localized devastation to fisheries infrastructure and the shrimp aquaculture sector is also reported, with shrimp hatcheries badly hit, particularly in Satkhira, Khulna and Cox'Bazar districts.\n",
      "\n",
      "SUMMARY:\n",
      "Localized devastation to fisheries infrastructure and the shrimp aquaculture sector is also reported, with shrimp hatcheries badly hit, particularly in Satkhira, Khulna and Cox'Bazar districts.\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "sample = dft[[\"message\", \"summary\"]].sample(10, random_state=42)\n",
    "\n",
    "for _, row in sample.iterrows():\n",
    "    print(\"MESSAGE:\")\n",
    "    print(row[\"message\"])\n",
    "    print(\"\\nSUMMARY:\")\n",
    "    print(row[\"summary\"])\n",
    "    print(\"=\" * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67096178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL:\n",
      "Mined roads and footpaths impede repatriation of refugees and returnees, and mined farmland precludes agricultural production. On 3 August, rioters attacked Alang Asaude in western Seram. Besides Marburg and Ebola, other zoonotic diseases that have struck around the world are swine flu, H1N1 (bird flu), bubonic plague and rabies. It will also finance a 60 km natural gas pipeline that will improve the reliability of gas supply to the plant, and an 11 km electricity transmission line so that power from the plant can be distributed to consumers. I am equally concerned about violations by anti-government forces, including murder, extrajudicial execution and torture as well as the recently increased use of improvised explosive devices. Emphasizes the importance of regional cooperation and coordination in disaster reduction, including enhanced institutional arrangements, technical cooperation based on most effective technical equipment and capacity building to effectively address the impact of natural disasters;. In a statement issued on 28 November, Al-Shabab accused the agencies of financing, aiding and abetting subversive groups seeking to destroy the basic tenets of Islamic penal system\", adding that the agencies were \"persistently galvanizing the local population against the full establishment of Islamic Sharia system\".\n",
      "\n",
      "SUMMARY:\n",
      "I am equally concerned about violations by anti-government forces, including murder, extrajudicial execution and torture as well as the recently increased use of improvised explosive devices.. In a statement issued on 28 November, Al-Shabab accused the agencies of financing, aiding and abetting subversive groups seeking to destroy the basic tenets of Islamic penal system\", adding that the agencies were \"persistently galvanizing the local population against the full establishment of Islamic Sharia system\".\n",
      "====================================================================================================\n",
      "ORIGINAL:\n",
      "This is in line with the overall explosion in crowdfunding globally, an industry that grew in value from $1.5 billion in 2011 to $16.2 billion in 2014, according to industry research firm Massolution, with a further doubling projected in 2015.\n",
      "\n",
      "SUMMARY:\n",
      "This is in line with the overall explosion in crowdfunding globally, an industry that grew in value from $1.5 billion in 2011 to $16.2 billion in 2014, according to industry research firm Massolution, with a further doubling projected in 2015.\n",
      "====================================================================================================\n",
      "ORIGINAL:\n",
      "Our team is still evaluating the damage in the cellar in Peumo.. In Santiago, our main office is fine.. Good.. http://bit.ly/dllDxS\n",
      "\n",
      "SUMMARY:\n",
      "Our team is still evaluating the damage in the cellar in Peumo.. In Santiago, our main office is fine.. Good.. http://bit.ly/dllDxS\n",
      "====================================================================================================\n",
      "ORIGINAL:\n",
      "Approximately 300,000 victims are still living in substandard conditions (i.e., weathered tents and temporary shelters of stone, wood and corrugated iron sheeting) while only 30% of construction of new homes has been completed.\n",
      "\n",
      "SUMMARY:\n",
      "Approximately 300,000 victims are still living in substandard conditions (i.e., weathered tents and temporary shelters of stone, wood and corrugated iron sheeting) while only 30% of construction of new homes has been completed.\n",
      "====================================================================================================\n",
      "ORIGINAL:\n",
      "#HoesBeTwerkin to Twerk up the east coast . Ohhhh wait .. . #HurricaneSandy\n",
      "\n",
      "SUMMARY:\n",
      "#HoesBeTwerkin to Twerk up the east coast .. #HurricaneSandy\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test only messages with multiple sentences\n",
    "\n",
    "long_msgs = dft[\n",
    "    dft[\"message\"].str.count(r\"\\.\") >= 2\n",
    "].sample(5, random_state=42)\n",
    "\n",
    "for _, row in long_msgs.iterrows():\n",
    "    print(\"ORIGINAL:\")\n",
    "    print(row[\"message\"])\n",
    "    print(\"\\nSUMMARY:\")\n",
    "    print(row[\"summary\"])\n",
    "    print(\"=\" * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "079a1570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary_debug(message, max_sentences=2):\n",
    "    sentences = safe_sentence_split(message)\n",
    "    \n",
    "    print(f\"Total sentences detected: {len(sentences)}\")\n",
    "    \n",
    "    if len(sentences) <= max_sentences:\n",
    "        print(\"→ Returning original (too short to summarize)\")\n",
    "        return message.strip()\n",
    "    \n",
    "    embeddings = np.vstack([encode_sentence(s) for s in sentences])\n",
    "    centroid = embeddings.mean(axis=0, keepdims=True)\n",
    "    sims = cosine_similarity(embeddings, centroid).flatten()\n",
    "    \n",
    "    for i, (s, sc) in enumerate(zip(sentences, sims)):\n",
    "        print(f\"[{i}] score={sc:.4f} | {s}\")\n",
    "    \n",
    "    top_ids = np.argsort(sims)[::-1][:max_sentences]\n",
    "    return \" \".join([sentences[i] for i in top_ids])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
